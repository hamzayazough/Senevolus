{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd4d6d2-0dc2-4e49-a28d-ab8d3e3c8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "DeepFace is working correctly!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from deepface import DeepFace\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Test DeepFace functionality\n",
    "try:\n",
    "    models = DeepFace.build_model(\"Facenet\")\n",
    "    print(\"DeepFace is working correctly!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing DeepFace: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418d7a73-c102-40e6-9cc5-2a6d9e207a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Verification result: {'verified': True, 'distance': 0.2367091726586319, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine'}\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "image1_path = r\"C:\\Users\\hamza\\Documents\\dataset\\older_people\\img1_person1.jpg\"\n",
    "image2_path = r\"C:\\Users\\hamza\\Documents\\dataset\\older_people\\img2_person1.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "verification = DeepFace.verify(image1_path, image2_path, model_name=\"Facenet\")\n",
    "print(\"Verification result:\", verification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441ffb62-26c0-429e-a54d-85dc020661c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN ## library for face detection we are importing the face detection model MTCNN \n",
    "import cv2 ## OpenCV the goat of image processing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be615650-ef11-4c58-8353-78cdb1a06edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN() ## instancing the face detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1420a338-e835-42a6-95fe-1e660040b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing image method created\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path, target_size=(160, 160)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) ## standadizing the color format\n",
    "    faces = detector.detect_faces(img) ## return a list of detected faces\n",
    "    if len(faces) > 0:\n",
    "        x, y, w, h = faces[0]['box'] ## fetching the coordinates and dimensions of the first detected face\n",
    "        face = img[y:y+h, x:x+w] ## cropping the image to only keep the face\n",
    "        face = cv2.resize(face, target_size) ## 160x160 pixel\n",
    "        return face / 255.0\n",
    "    return None\n",
    "\n",
    "print(\"preprocessing image method created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e450e72-f66a-40b6-9884-002f492fd15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing all images in the dataset\n"
     ]
    }
   ],
   "source": [
    "for category in [\"young_adults\", \"older_people\"]:\n",
    "    folder = f\"C:/Users/hamza/Documents/dataset/{category}\"\n",
    "    for file_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file_name)\n",
    "        processed_face = preprocess_image(image_path)\n",
    "        if processed_face is not None:\n",
    "            output_path = os.path.join(folder, f\"processed_{file_name}\")\n",
    "            cv2.imwrite(output_path, processed_face * 255)\n",
    "print(\"processed all images in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0deb1a-bc04-428d-a64b-5f4aa45e75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98d003aa-6dde-4028-a6b8-8b175ff47b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "Keras version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(\"Keras version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7348d3f6-fbea-4127-8ab2-09e01232d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File keys: ['AvgPool', 'Block17_10_Activation', 'Block17_10_Branch_0_Conv2d_1x1', 'Block17_10_Branch_0_Conv2d_1x1_Activation', 'Block17_10_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_10_Branch_1_Conv2d_0a_1x1', 'Block17_10_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_10_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_10_Branch_1_Conv2d_0b_1x7', 'Block17_10_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_10_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_10_Branch_1_Conv2d_0c_7x1', 'Block17_10_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_10_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_10_Concatenate', 'Block17_10_Conv2d_1x1', 'Block17_10_ScaleSum', 'Block17_1_Activation', 'Block17_1_Branch_0_Conv2d_1x1', 'Block17_1_Branch_0_Conv2d_1x1_Activation', 'Block17_1_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_1_Branch_1_Conv2d_0a_1x1', 'Block17_1_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_1_Branch_1_Conv2d_0b_1x7', 'Block17_1_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_1_Branch_1_Conv2d_0c_7x1', 'Block17_1_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_1_Concatenate', 'Block17_1_Conv2d_1x1', 'Block17_1_ScaleSum', 'Block17_2_Activation', 'Block17_2_Branch_0_Conv2d_1x1', 'Block17_2_Branch_0_Conv2d_1x1_Activation', 'Block17_2_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_2_Branch_1_Conv2d_0a_1x1', 'Block17_2_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_2_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_2_Branch_1_Conv2d_0b_1x7', 'Block17_2_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_2_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_2_Branch_1_Conv2d_0c_7x1', 'Block17_2_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_2_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_2_Concatenate', 'Block17_2_Conv2d_1x1', 'Block17_2_ScaleSum', 'Block17_3_Activation', 'Block17_3_Branch_0_Conv2d_1x1', 'Block17_3_Branch_0_Conv2d_1x1_Activation', 'Block17_3_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_3_Branch_1_Conv2d_0a_1x1', 'Block17_3_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_3_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_3_Branch_1_Conv2d_0b_1x7', 'Block17_3_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_3_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_3_Branch_1_Conv2d_0c_7x1', 'Block17_3_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_3_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_3_Concatenate', 'Block17_3_Conv2d_1x1', 'Block17_3_ScaleSum', 'Block17_4_Activation', 'Block17_4_Branch_0_Conv2d_1x1', 'Block17_4_Branch_0_Conv2d_1x1_Activation', 'Block17_4_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_4_Branch_1_Conv2d_0a_1x1', 'Block17_4_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_4_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_4_Branch_1_Conv2d_0b_1x7', 'Block17_4_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_4_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_4_Branch_1_Conv2d_0c_7x1', 'Block17_4_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_4_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_4_Concatenate', 'Block17_4_Conv2d_1x1', 'Block17_4_ScaleSum', 'Block17_5_Activation', 'Block17_5_Branch_0_Conv2d_1x1', 'Block17_5_Branch_0_Conv2d_1x1_Activation', 'Block17_5_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_5_Branch_1_Conv2d_0a_1x1', 'Block17_5_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_5_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_5_Branch_1_Conv2d_0b_1x7', 'Block17_5_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_5_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_5_Branch_1_Conv2d_0c_7x1', 'Block17_5_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_5_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_5_Concatenate', 'Block17_5_Conv2d_1x1', 'Block17_5_ScaleSum', 'Block17_6_Activation', 'Block17_6_Branch_0_Conv2d_1x1', 'Block17_6_Branch_0_Conv2d_1x1_Activation', 'Block17_6_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_6_Branch_1_Conv2d_0a_1x1', 'Block17_6_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_6_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_6_Branch_1_Conv2d_0b_1x7', 'Block17_6_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_6_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_6_Branch_1_Conv2d_0c_7x1', 'Block17_6_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_6_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_6_Concatenate', 'Block17_6_Conv2d_1x1', 'Block17_6_ScaleSum', 'Block17_7_Activation', 'Block17_7_Branch_0_Conv2d_1x1', 'Block17_7_Branch_0_Conv2d_1x1_Activation', 'Block17_7_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_7_Branch_1_Conv2d_0a_1x1', 'Block17_7_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_7_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_7_Branch_1_Conv2d_0b_1x7', 'Block17_7_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_7_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_7_Branch_1_Conv2d_0c_7x1', 'Block17_7_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_7_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_7_Concatenate', 'Block17_7_Conv2d_1x1', 'Block17_7_ScaleSum', 'Block17_8_Activation', 'Block17_8_Branch_0_Conv2d_1x1', 'Block17_8_Branch_0_Conv2d_1x1_Activation', 'Block17_8_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_8_Branch_1_Conv2d_0a_1x1', 'Block17_8_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_8_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_8_Branch_1_Conv2d_0b_1x7', 'Block17_8_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_8_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_8_Branch_1_Conv2d_0c_7x1', 'Block17_8_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_8_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_8_Concatenate', 'Block17_8_Conv2d_1x1', 'Block17_8_ScaleSum', 'Block17_9_Activation', 'Block17_9_Branch_0_Conv2d_1x1', 'Block17_9_Branch_0_Conv2d_1x1_Activation', 'Block17_9_Branch_0_Conv2d_1x1_BatchNorm', 'Block17_9_Branch_1_Conv2d_0a_1x1', 'Block17_9_Branch_1_Conv2d_0a_1x1_Activation', 'Block17_9_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block17_9_Branch_1_Conv2d_0b_1x7', 'Block17_9_Branch_1_Conv2d_0b_1x7_Activation', 'Block17_9_Branch_1_Conv2d_0b_1x7_BatchNorm', 'Block17_9_Branch_1_Conv2d_0c_7x1', 'Block17_9_Branch_1_Conv2d_0c_7x1_Activation', 'Block17_9_Branch_1_Conv2d_0c_7x1_BatchNorm', 'Block17_9_Concatenate', 'Block17_9_Conv2d_1x1', 'Block17_9_ScaleSum', 'Block35_1_Activation', 'Block35_1_Branch_0_Conv2d_1x1', 'Block35_1_Branch_0_Conv2d_1x1_Activation', 'Block35_1_Branch_0_Conv2d_1x1_BatchNorm', 'Block35_1_Branch_1_Conv2d_0a_1x1', 'Block35_1_Branch_1_Conv2d_0a_1x1_Activation', 'Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block35_1_Branch_1_Conv2d_0b_3x3', 'Block35_1_Branch_1_Conv2d_0b_3x3_Activation', 'Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Block35_1_Branch_2_Conv2d_0a_1x1', 'Block35_1_Branch_2_Conv2d_0a_1x1_Activation', 'Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Block35_1_Branch_2_Conv2d_0b_3x3', 'Block35_1_Branch_2_Conv2d_0b_3x3_Activation', 'Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Block35_1_Branch_2_Conv2d_0c_3x3', 'Block35_1_Branch_2_Conv2d_0c_3x3_Activation', 'Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm', 'Block35_1_Concatenate', 'Block35_1_Conv2d_1x1', 'Block35_1_ScaleSum', 'Block35_2_Activation', 'Block35_2_Branch_0_Conv2d_1x1', 'Block35_2_Branch_0_Conv2d_1x1_Activation', 'Block35_2_Branch_0_Conv2d_1x1_BatchNorm', 'Block35_2_Branch_1_Conv2d_0a_1x1', 'Block35_2_Branch_1_Conv2d_0a_1x1_Activation', 'Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block35_2_Branch_1_Conv2d_0b_3x3', 'Block35_2_Branch_1_Conv2d_0b_3x3_Activation', 'Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Block35_2_Branch_2_Conv2d_0a_1x1', 'Block35_2_Branch_2_Conv2d_0a_1x1_Activation', 'Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Block35_2_Branch_2_Conv2d_0b_3x3', 'Block35_2_Branch_2_Conv2d_0b_3x3_Activation', 'Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Block35_2_Branch_2_Conv2d_0c_3x3', 'Block35_2_Branch_2_Conv2d_0c_3x3_Activation', 'Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm', 'Block35_2_Concatenate', 'Block35_2_Conv2d_1x1', 'Block35_2_ScaleSum', 'Block35_3_Activation', 'Block35_3_Branch_0_Conv2d_1x1', 'Block35_3_Branch_0_Conv2d_1x1_Activation', 'Block35_3_Branch_0_Conv2d_1x1_BatchNorm', 'Block35_3_Branch_1_Conv2d_0a_1x1', 'Block35_3_Branch_1_Conv2d_0a_1x1_Activation', 'Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block35_3_Branch_1_Conv2d_0b_3x3', 'Block35_3_Branch_1_Conv2d_0b_3x3_Activation', 'Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Block35_3_Branch_2_Conv2d_0a_1x1', 'Block35_3_Branch_2_Conv2d_0a_1x1_Activation', 'Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Block35_3_Branch_2_Conv2d_0b_3x3', 'Block35_3_Branch_2_Conv2d_0b_3x3_Activation', 'Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Block35_3_Branch_2_Conv2d_0c_3x3', 'Block35_3_Branch_2_Conv2d_0c_3x3_Activation', 'Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm', 'Block35_3_Concatenate', 'Block35_3_Conv2d_1x1', 'Block35_3_ScaleSum', 'Block35_4_Activation', 'Block35_4_Branch_0_Conv2d_1x1', 'Block35_4_Branch_0_Conv2d_1x1_Activation', 'Block35_4_Branch_0_Conv2d_1x1_BatchNorm', 'Block35_4_Branch_1_Conv2d_0a_1x1', 'Block35_4_Branch_1_Conv2d_0a_1x1_Activation', 'Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block35_4_Branch_1_Conv2d_0b_3x3', 'Block35_4_Branch_1_Conv2d_0b_3x3_Activation', 'Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Block35_4_Branch_2_Conv2d_0a_1x1', 'Block35_4_Branch_2_Conv2d_0a_1x1_Activation', 'Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Block35_4_Branch_2_Conv2d_0b_3x3', 'Block35_4_Branch_2_Conv2d_0b_3x3_Activation', 'Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Block35_4_Branch_2_Conv2d_0c_3x3', 'Block35_4_Branch_2_Conv2d_0c_3x3_Activation', 'Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm', 'Block35_4_Concatenate', 'Block35_4_Conv2d_1x1', 'Block35_4_ScaleSum', 'Block35_5_Activation', 'Block35_5_Branch_0_Conv2d_1x1', 'Block35_5_Branch_0_Conv2d_1x1_Activation', 'Block35_5_Branch_0_Conv2d_1x1_BatchNorm', 'Block35_5_Branch_1_Conv2d_0a_1x1', 'Block35_5_Branch_1_Conv2d_0a_1x1_Activation', 'Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block35_5_Branch_1_Conv2d_0b_3x3', 'Block35_5_Branch_1_Conv2d_0b_3x3_Activation', 'Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Block35_5_Branch_2_Conv2d_0a_1x1', 'Block35_5_Branch_2_Conv2d_0a_1x1_Activation', 'Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Block35_5_Branch_2_Conv2d_0b_3x3', 'Block35_5_Branch_2_Conv2d_0b_3x3_Activation', 'Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Block35_5_Branch_2_Conv2d_0c_3x3', 'Block35_5_Branch_2_Conv2d_0c_3x3_Activation', 'Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm', 'Block35_5_Concatenate', 'Block35_5_Conv2d_1x1', 'Block35_5_ScaleSum', 'Block8_1_Activation', 'Block8_1_Branch_0_Conv2d_1x1', 'Block8_1_Branch_0_Conv2d_1x1_Activation', 'Block8_1_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_1_Branch_1_Conv2d_0a_1x1', 'Block8_1_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_1_Branch_1_Conv2d_0b_1x3', 'Block8_1_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_1_Branch_1_Conv2d_0c_3x1', 'Block8_1_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_1_Concatenate', 'Block8_1_Conv2d_1x1', 'Block8_1_ScaleSum', 'Block8_2_Activation', 'Block8_2_Branch_0_Conv2d_1x1', 'Block8_2_Branch_0_Conv2d_1x1_Activation', 'Block8_2_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_2_Branch_1_Conv2d_0a_1x1', 'Block8_2_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_2_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_2_Branch_1_Conv2d_0b_1x3', 'Block8_2_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_2_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_2_Branch_1_Conv2d_0c_3x1', 'Block8_2_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_2_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_2_Concatenate', 'Block8_2_Conv2d_1x1', 'Block8_2_ScaleSum', 'Block8_3_Activation', 'Block8_3_Branch_0_Conv2d_1x1', 'Block8_3_Branch_0_Conv2d_1x1_Activation', 'Block8_3_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_3_Branch_1_Conv2d_0a_1x1', 'Block8_3_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_3_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_3_Branch_1_Conv2d_0b_1x3', 'Block8_3_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_3_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_3_Branch_1_Conv2d_0c_3x1', 'Block8_3_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_3_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_3_Concatenate', 'Block8_3_Conv2d_1x1', 'Block8_3_ScaleSum', 'Block8_4_Activation', 'Block8_4_Branch_0_Conv2d_1x1', 'Block8_4_Branch_0_Conv2d_1x1_Activation', 'Block8_4_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_4_Branch_1_Conv2d_0a_1x1', 'Block8_4_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_4_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_4_Branch_1_Conv2d_0b_1x3', 'Block8_4_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_4_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_4_Branch_1_Conv2d_0c_3x1', 'Block8_4_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_4_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_4_Concatenate', 'Block8_4_Conv2d_1x1', 'Block8_4_ScaleSum', 'Block8_5_Activation', 'Block8_5_Branch_0_Conv2d_1x1', 'Block8_5_Branch_0_Conv2d_1x1_Activation', 'Block8_5_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_5_Branch_1_Conv2d_0a_1x1', 'Block8_5_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_5_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_5_Branch_1_Conv2d_0b_1x3', 'Block8_5_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_5_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_5_Branch_1_Conv2d_0c_3x1', 'Block8_5_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_5_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_5_Concatenate', 'Block8_5_Conv2d_1x1', 'Block8_5_ScaleSum', 'Block8_6_Branch_0_Conv2d_1x1', 'Block8_6_Branch_0_Conv2d_1x1_Activation', 'Block8_6_Branch_0_Conv2d_1x1_BatchNorm', 'Block8_6_Branch_1_Conv2d_0a_1x1', 'Block8_6_Branch_1_Conv2d_0a_1x1_Activation', 'Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Block8_6_Branch_1_Conv2d_0b_1x3', 'Block8_6_Branch_1_Conv2d_0b_1x3_Activation', 'Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm', 'Block8_6_Branch_1_Conv2d_0c_3x1', 'Block8_6_Branch_1_Conv2d_0c_3x1_Activation', 'Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm', 'Block8_6_Concatenate', 'Block8_6_Conv2d_1x1', 'Block8_6_ScaleSum', 'Bottleneck', 'Bottleneck_BatchNorm', 'Conv2d_1a_3x3', 'Conv2d_1a_3x3_Activation', 'Conv2d_1a_3x3_BatchNorm', 'Conv2d_2a_3x3', 'Conv2d_2a_3x3_Activation', 'Conv2d_2a_3x3_BatchNorm', 'Conv2d_2b_3x3', 'Conv2d_2b_3x3_Activation', 'Conv2d_2b_3x3_BatchNorm', 'Conv2d_3b_1x1', 'Conv2d_3b_1x1_Activation', 'Conv2d_3b_1x1_BatchNorm', 'Conv2d_4a_3x3', 'Conv2d_4a_3x3_Activation', 'Conv2d_4a_3x3_BatchNorm', 'Conv2d_4b_3x3', 'Conv2d_4b_3x3_Activation', 'Conv2d_4b_3x3_BatchNorm', 'Dropout', 'MaxPool_3a_3x3', 'Mixed_6a', 'Mixed_6a_Branch_0_Conv2d_1a_3x3', 'Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation', 'Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm', 'Mixed_6a_Branch_1_Conv2d_0a_1x1', 'Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation', 'Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Mixed_6a_Branch_1_Conv2d_0b_3x3', 'Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation', 'Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm', 'Mixed_6a_Branch_1_Conv2d_1a_3x3', 'Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation', 'Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm', 'Mixed_6a_Branch_2_MaxPool_1a_3x3', 'Mixed_7a', 'Mixed_7a_Branch_0_Conv2d_0a_1x1', 'Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation', 'Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm', 'Mixed_7a_Branch_0_Conv2d_1a_3x3', 'Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation', 'Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm', 'Mixed_7a_Branch_1_Conv2d_0a_1x1', 'Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation', 'Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm', 'Mixed_7a_Branch_1_Conv2d_1a_3x3', 'Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation', 'Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm', 'Mixed_7a_Branch_2_Conv2d_0a_1x1', 'Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation', 'Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm', 'Mixed_7a_Branch_2_Conv2d_0b_3x3', 'Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation', 'Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm', 'Mixed_7a_Branch_2_Conv2d_1a_3x3', 'Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation', 'Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm', 'Mixed_7a_Branch_3_MaxPool_1a_3x3', 'input_1']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab87f5f0-72c5-4f29-8604-3bf8f55784ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-facenet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip available: 22.3 -> 24.3.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mtcnn in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from keras-facenet) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.4.2 in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from mtcnn->keras-facenet) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from mtcnn->keras-facenet) (4.3.3)\n",
      "Building wheels for collected packages: keras-facenet\n",
      "  Building wheel for keras-facenet (setup.py): started\n",
      "  Building wheel for keras-facenet (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10387 sha256=c6c37c5da17fec88d1e3b6b033781b1c71b15c5e9b6ff757d61b24ebb5a47c4d\n",
      "  Stored in directory: c:\\users\\hamza\\appdata\\local\\pip\\cache\\wheels\\1e\\bd\\48\\10eff5194e240382ed4fdcfadf85950a011e68b16b56e65a49\n",
      "Successfully built keras-facenet\n",
      "Installing collected packages: keras-facenet\n",
      "Successfully installed keras-facenet-0.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install keras-facenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d067582f-762c-4834-adec-573bf8260712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceNet model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras_facenet import FaceNet\n",
    "\n",
    "# Initialize FaceNet\n",
    "embedder = FaceNet()\n",
    "\n",
    "print(\"FaceNet model loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8b997e6-ed11-4ab2-adf9-337de3193e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras_facenet import FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c69bc9f-bbc5-4d3b-b429-f5106e3a1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FaceNet()\n",
    "def get_embedding(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converting to RGB\n",
    "    return embedder.embeddings([img])[0]  # Extract embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30e571c6-76ad-4581-b426-f52666e6744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Embeddings extracted and saved!\n"
     ]
    }
   ],
   "source": [
    "embeddings = {\"young_adults\": [], \"older_people\": []}\n",
    "for category in [\"young_adults\", \"older_people\"]:\n",
    "    folder = f\"C:/Users/hamza/Documents/dataset/{category}\"\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.startswith(\"processed_\"):  # Use only preprocessed images to avoid bugs \n",
    "            image_path = os.path.join(folder, file_name)\n",
    "            embedding = get_embedding(image_path)\n",
    "            embeddings[category].append(embedding)\n",
    "\n",
    "# Save embeddings to disk for later use\n",
    "np.save(\"young_adults_embeddings.npy\", embeddings[\"young_adults\"])\n",
    "np.save(\"older_people_embeddings.npy\", embeddings[\"older_people\"])\n",
    "print(\"Embeddings extracted and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "423df90b-ba08-4f06-80f4-413650cc6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip available: 22.3 -> 24.3.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     --------------------------------------- 11.1/11.1 MB 28.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hamza\\documents\\senevolus\\backend\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40d3bffb-7a92-423f-a3c8-b775b97cd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## configuring the labels\n",
    "young_adults_embeddings = np.load(\"young_adults_embeddings.npy\")\n",
    "older_people_embeddings = np.load(\"older_people_embeddings.npy\")\n",
    "\n",
    "young_adults_labels = np.zeros(len(young_adults_embeddings))\n",
    "older_people_labels = np.ones(len(older_people_embeddings))\n",
    "\n",
    "X = np.concatenate([young_adults_embeddings, older_people_embeddings], axis=0)\n",
    "y = np.concatenate([young_adults_labels, older_people_labels], axis=0)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47a3f632-3e25-41f8-9cbd-23262d8570f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         5\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Spliting our data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation of the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc68f982-7102-4b5d-bb2a-f96d8ab05313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(classifier, \"age_classifier.pkl\")\n",
    "print(\"Classifier saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f41cd1d5-3ff5-442c-93ff-da9005aeed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n",
      "Predicted Age Group: Older Person\n"
     ]
    }
   ],
   "source": [
    "def predict_age_group(image_path):\n",
    "    embedding = get_embedding(image_path)\n",
    "    prediction = classifier.predict([embedding])\n",
    "    return \"Young Adult\" if prediction[0] == 0 else \"Older Person\"\n",
    "\n",
    "image_path = \"testing-images/img1_test6.jpg\"\n",
    "print(\"Predicted Age Group:\", predict_age_group(image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "094fc26d-cd55-46e6-ba72-12b3fc0bad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Are the same person? False (Distance: 1.2898436784744263)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def verify_faces(image1_path, image2_path, threshold=0.8):\n",
    "    embedding1 = get_embedding(image1_path)\n",
    "    embedding2 = get_embedding(image2_path)\n",
    "    distance = euclidean(embedding1, embedding2)\n",
    "    return distance < threshold, distance\n",
    "\n",
    "# Little test on images\n",
    "image1 = \"testing-images/img1_test6.jpg\"\n",
    "image2 = \"testing-images/img2_test4.jpg\"\n",
    "is_same, distance = verify_faces(image1, image2)\n",
    "print(f\"Are the same person? {is_same} (Distance: {distance})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6d33b51-ee0b-4da6-9ff6-490fcc5cfae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Person 1 - Same Person Test: True (Distance: 0.598515510559082)\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Person 1 vs Person 2 - Different Person Test: False (Distance: 1.3701331615447998)\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Person 1 vs Person 3 - Different Person Test: False (Distance: 1.3245395421981812)\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Person 1 vs Person 4 - Different Person Test: False (Distance: 1.337578535079956)\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Person 1 vs Person 5 - Different Person Test: False (Distance: 1.1954272985458374)\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Person 1 vs Person 6 - Different Person Test: False (Distance: 1.38690984249115)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Person 2 - Same Person Test: False (Distance: 1.0409458875656128)\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Person 2 vs Person 1 - Different Person Test: False (Distance: 1.5274860858917236)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Person 2 vs Person 3 - Different Person Test: True (Distance: 0.7879627346992493)\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Person 2 vs Person 4 - Different Person Test: False (Distance: 1.3694344758987427)\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Person 2 vs Person 5 - Different Person Test: False (Distance: 1.091005802154541)\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Person 2 vs Person 6 - Different Person Test: False (Distance: 1.16072678565979)\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Person 3 - Same Person Test: True (Distance: 0.7602003812789917)\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Person 3 vs Person 1 - Different Person Test: False (Distance: 1.3030532598495483)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Person 3 vs Person 2 - Different Person Test: False (Distance: 1.2659039497375488)\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Person 3 vs Person 4 - Different Person Test: False (Distance: 1.4096050262451172)\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Person 3 vs Person 5 - Different Person Test: False (Distance: 1.1890912055969238)\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Person 3 vs Person 6 - Different Person Test: False (Distance: 1.32427179813385)\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Person 4 - Same Person Test: True (Distance: 0.6904311776161194)\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Person 4 vs Person 1 - Different Person Test: False (Distance: 1.2655096054077148)\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Person 4 vs Person 2 - Different Person Test: False (Distance: 1.4355005025863647)\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Person 4 vs Person 3 - Different Person Test: False (Distance: 1.433563232421875)\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Person 4 vs Person 5 - Different Person Test: False (Distance: 1.26790189743042)\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Person 4 vs Person 6 - Different Person Test: False (Distance: 1.3259998559951782)\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Person 5 - Same Person Test: True (Distance: 0.6437457799911499)\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Person 5 vs Person 1 - Different Person Test: False (Distance: 1.1582058668136597)\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Person 5 vs Person 2 - Different Person Test: False (Distance: 1.0163525342941284)\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Person 5 vs Person 3 - Different Person Test: False (Distance: 0.9908509850502014)\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Person 5 vs Person 4 - Different Person Test: False (Distance: 1.3511979579925537)\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Person 5 vs Person 6 - Different Person Test: True (Distance: 0.769245445728302)\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Person 6 - Same Person Test: True (Distance: 0.48046502470970154)\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Person 6 vs Person 1 - Different Person Test: False (Distance: 1.434678077697754)\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Person 6 vs Person 2 - Different Person Test: False (Distance: 1.040385127067566)\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Person 6 vs Person 3 - Different Person Test: False (Distance: 0.9642824530601501)\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Person 6 vs Person 4 - Different Person Test: False (Distance: 1.2898436784744263)\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Person 6 vs Person 5 - Different Person Test: False (Distance: 0.8844952583312988)\n",
      "Testing complete. Results saved to 'verification_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Function to verify faces\n",
    "def verify_faces(image1_path, image2_path, threshold=0.8):\n",
    "    embedding1 = get_embedding(image1_path)\n",
    "    embedding2 = get_embedding(image2_path)\n",
    "    distance = euclidean(embedding1, embedding2)\n",
    "    return distance < threshold, distance\n",
    "\n",
    "folder_path = \"testing-images\"\n",
    "num_people = 6 \n",
    "threshold = 0.8\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1, num_people + 1):\n",
    "    img1 = f\"{folder_path}/img1_test{i}.jpg\"\n",
    "    img2 = f\"{folder_path}/img2_test{i}.jpg\"\n",
    "    is_same, distance = verify_faces(img1, img2, threshold)\n",
    "    results.append({\n",
    "        \"Test Type\": \"Same Person\",\n",
    "        \"Person\": i,\n",
    "        \"Image 1\": img1,\n",
    "        \"Image 2\": img2,\n",
    "        \"Model Prediction\": \"Same\" if is_same else \"Different\",\n",
    "        \"Distance\": distance\n",
    "    })\n",
    "    print(f\"Person {i} - Same Person Test: {is_same} (Distance: {distance})\")\n",
    "\n",
    "    for j in range(1, num_people + 1):\n",
    "        if i != j: \n",
    "            img_other = f\"{folder_path}/img2_test{j}.jpg\"\n",
    "            is_same, distance = verify_faces(img1, img_other, threshold)\n",
    "            results.append({\n",
    "                \"Test Type\": \"Different Person\",\n",
    "                \"Person 1\": i,\n",
    "                \"Person 2\": j,\n",
    "                \"Image 1\": img1,\n",
    "                \"Image 2\": img_other,\n",
    "                \"Model Prediction\": \"Same\" if is_same else \"Different\",\n",
    "                \"Distance\": distance\n",
    "            })\n",
    "            print(f\"Person {i} vs Person {j} - Different Person Test: {is_same} (Distance: {distance})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1beba-dcf5-49d5-8a2b-d99a65da56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"verification_results.csv\", index=False)\n",
    "print(\"Testing complete. Results saved to 'verification_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3406a-e87b-4693-9a9a-dce20d9db25e",
   "metadata": {},
   "source": [
    "## Not as good as expected to differentiate other people but due to time constraints we are gonna go with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1715752-cb91-4cb9-af5f-f363c8889220",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the classifier\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mclf\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic_regression_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier saved successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Saving the classifier\n",
    "joblib.dump(clf, \"logistic_regression_model.pkl\")\n",
    "print(\"Classifier saved successfully!\")\n",
    "\n",
    "threshold = 0.8\n",
    "with open(\"threshold.txt\", \"w\") as f:\n",
    "    f.write(str(threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474b0cc-6f52-4398-8357-c6903a9de77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
